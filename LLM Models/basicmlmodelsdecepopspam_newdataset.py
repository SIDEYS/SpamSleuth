# -*- coding: utf-8 -*-
"""basicMLmodelsDecepOpSpam_NewDataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1spFXizto6sZr17L_OjAXoMcEyuDCOkhh
"""

# # This Python 3 environment comes with many helpful analytics libraries installed
# # It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python
# # For example, here's several helpful packages to load in

# import numpy as np # linear algebra
# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# # Input data files are available in the "../input/" directory.
# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

# import os
# for dirname, _, filenames in os.walk('/kaggle/input'):
#     for filename in filenames:
#         print(os.path.join(dirname, filename))

# # Any results you write to the current directory are saved as output.

import re
import string
from nltk.corpus import stopwords
from bs4 import BeautifulSoup
import nltk
from nltk.corpus import stopwords
from nltk.stem import SnowballStemmer

import numpy as np # linear algebra
import pandas as pd

df = pd.read_csv('/content/fake_review.csv')

df.head()

df = df.sample(frac=1)

df.head()

df.head()

#dataset description #truthful=1 deceptive=0
df.groupby('label').describe()

def clean_text(text):

    ## Remove puncuation
    text = text.translate(string.punctuation)

    ## Convert words to lower case and split them
    text = text.lower().split()

    ## Remove stop words
    stops = set(stopwords.words("english"))
    text = [w for w in text if not w in stops and len(w) >= 3]

    text = " ".join(text)

    # Clean the text
    text = re.sub(r"[^A-Za-z0-9^,!.\/'+-=]", " ", text)
    text = re.sub(r"what's", "what is ", text)
    text = re.sub(r"\'s", " ", text)
    text = re.sub(r"\'ve", " have ", text)
    text = re.sub(r"n't", " not ", text)
    text = re.sub(r"i'm", "i am ", text)
    text = re.sub(r"\'re", " are ", text)
    text = re.sub(r"\'d", " would ", text)
    text = re.sub(r"\'ll", " will ", text)
    text = re.sub(r",", " ", text)
    text = re.sub(r"\.", " ", text)
    text = re.sub(r"!", " ! ", text)
    text = re.sub(r"\/", " ", text)
    text = re.sub(r"\^", " ^ ", text)
    text = re.sub(r"\+", " + ", text)
    text = re.sub(r"\-", " - ", text)
    text = re.sub(r"\=", " = ", text)
    text = re.sub(r"'", " ", text)
    text = re.sub(r"(\d+)(k)", r"\g<1>000", text)
    text = re.sub(r":", " : ", text)
    text = re.sub(r" e g ", " eg ", text)
    text = re.sub(r" b g ", " bg ", text)
    text = re.sub(r" u s ", " american ", text)
    text = re.sub(r"\0s", "0", text)
    text = re.sub(r" 9 11 ", "911", text)
    text = re.sub(r"e - mail", "email", text)
    text = re.sub(r"j k", "jk", text)
    text = re.sub(r"\s{2,}", " ", text)

    text = text.split()
    stemmer = SnowballStemmer('english')
    stemmed_words = [stemmer.stem(word) for word in text]
    text = " ".join(stemmed_words)

    return text

# Some preprocesssing that will be common to all the text classification methods

puncts = [',', '.', '"', ':', ')', '(', '-', '!', '?', '|', ';', "'", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\', '•',  '~', '@', '£',
 '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…',
 '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─',
 '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞',
 '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]

def clean_char(x):
    x = str(x)
    for punct in puncts:
        if punct in x:
            x = x.replace(punct, f' {punct} ')
    return x

def clean_numbers(x):
    if bool(re.search(r'\d', x)):
        x = re.sub('[0-9]{5,}', '#####', x)
        x = re.sub('[0-9]{4}', '####', x)
        x = re.sub('[0-9]{3}', '###', x)
        x = re.sub('[0-9]{2}', '##', x)
    return x

df['text'] = df['text'].map(lambda a: clean_numbers(a))

df['text'] = df['text'].map(lambda a: clean_char(a))

import nltk
 nltk.download('stopwords')

df['text'] = df['text'].map(lambda a: clean_text(a))

df['text']

df.describe()

df.info()

x = df['text']
y = df['label']

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.metrics import accuracy_score, confusion_matrix

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], random_state=3)
print('Number of rows in the total set: {}'.format(df.shape[0]))
print('Number of rows in the training set: {}'.format(X_train.shape[0]))
print('Number of rows in the test set: {}'.format(X_test.shape[0]))

X_train, X_test, y_train, y_test

from sklearn.feature_extraction.text import CountVectorizer
count_vector = CountVectorizer(ngram_range=(1,2), stop_words='english')
print(count_vector)

training_data = count_vector.fit_transform(X_train)
testing_data = count_vector.transform(X_test)

from sklearn.svm import SVC
svc = SVC()
svc.fit(training_data, y_train)

svc_predictions = svc.predict(testing_data)

from sklearn.metrics import accuracy_score
svcaccuracy = accuracy_score(y_test,svc_predictions)
print('Accuracy score: ', format(accuracy_score(y_test,svc_predictions)))
print('Precision score: ', format(precision_score(y_test,svc_predictions)))
print('Recall score: ', format(recall_score(y_test, svc_predictions)))
print('F1 score: ', format(f1_score(y_test, svc_predictions)))

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors = 7)
knn.fit(training_data, y_train)

knn_predictions = knn.predict(testing_data)

from sklearn.metrics import accuracy_score
knnaccuracy = accuracy_score(knn_predictions,y_test )
print('Accuracy score: ', format(accuracy_score(knn_predictions,y_test )))
print('Precision score: ', format(precision_score(y_test,knn_predictions)))
print('Recall score: ', format(recall_score(y_test, knn_predictions)))
print('F1 score: ', format(f1_score(y_test, knn_predictions)))

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
training_data1 = training_data.toarray()
gnb.fit(training_data1, y_train)

testing_data1= testing_data.toarray()
gnb_predictions = gnb.predict(testing_data1)

from sklearn.metrics import accuracy_score
gnb_accuracy = accuracy_score(gnb_predictions,y_test )
print('Accuracy score: ', format(accuracy_score(gnb_predictions,y_test )))
print('Precision score: ', format(precision_score(y_test,gnb_predictions)))
print('Recall score: ', format(recall_score(y_test, gnb_predictions)))
print('F1 score: ', format(f1_score(y_test, gnb_predictions)))

from sklearn.ensemble import GradientBoostingClassifier
gb = GradientBoostingClassifier()
gb.fit(training_data, y_train)

gb_predictions = gb.predict(testing_data)

from sklearn.metrics import accuracy_score
gbaccuracy = accuracy_score(y_test,gb_predictions)
print('Accuracy score: ', format(accuracy_score(y_test,gb_predictions)))
print('Precision score: ', format(precision_score(y_test,gb_predictions)))
print('Recall score: ', format(recall_score(y_test, gb_predictions)))
print('F1 score: ', format(f1_score(y_test, gb_predictions)))

# training a DescisionTreeClassifier
from sklearn.tree import DecisionTreeClassifier
dtree_model = DecisionTreeClassifier(max_depth = 2)
dtree_model.fit(training_data1, y_train)

dtree_model_predictions = dtree_model.predict(testing_data)

from sklearn.metrics import accuracy_score
gbaccuracy = accuracy_score(y_test,dtree_model_predictions)
print('Accuracy score: ', format(accuracy_score(y_test,dtree_model_predictions)))
print('Precision score: ', format(precision_score(y_test,dtree_model_predictions)))
print('Recall score: ', format(recall_score(y_test, dtree_model_predictions)))
print('F1 score: ', format(f1_score(y_test, dtree_model_predictions)))

from xgboost import XGBClassifier
xgb = XGBClassifier()
xgb.fit(training_data, y_train)

xgb_predictions = xgb.predict(testing_data)

from sklearn.metrics import accuracy_score
xgbaccuracy = accuracy_score(y_test,xgb_predictions)
print('Accuracy score: ', format(accuracy_score(y_test,xgb_predictions)))
print('Precision score: ', format(precision_score(y_test,xgb_predictions)))
print('Recall score: ', format(recall_score(y_test, xgb_predictions)))
print('F1 score: ', format(f1_score(y_test, xgb_predictions)))

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(training_data, y_train)

lrpredicted = lr.predict(testing_data)

from sklearn.metrics import accuracy_score
lr_accuracy = accuracy_score(lrpredicted,y_test )
print('Accuracy score: ', format(accuracy_score(lrpredicted,y_test )))
print('Precision score: ', format(precision_score(y_test,lrpredicted)))
print('Recall score: ', format(recall_score(y_test, lrpredicted)))
print('F1 score: ', format(f1_score(y_test, lrpredicted)))

print('Gausian Naive Bayes:',gnb_accuracy)
print('Decision tree:',dtree_accuracy)
print('Support Vector Classifier:',svcaccuracy)
print('K-Nearest Neighbour:',knnaccuracy)
print('LogisticRegression:',lr_accuracy)
print('GradientBoosting classifier:',gbaccuracy)
print('Xboost classifier:',xgbaccuracy)